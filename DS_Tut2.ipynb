{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataScience-Tut2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prachi Mehta\n",
        "\n",
        "UID: 2018130025\n",
        "\n",
        "DS Tutorial 2"
      ],
      "metadata": {
        "id": "O_9HiddDtQFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curse of Dimensionality:-\n",
        "\n",
        "The curse of dimensionality refers to the phenomena that occur when classifying, organizing, and analyzing high dimensional data that does not occur in low dimensional spaces, specifically the issue of data sparsity and closeness of data.\n",
        "\n",
        "Issues:-\n",
        "\n",
        "1) Sparsity of data occurs when moving to higher dimensions. the volume of the space represented grows so quickly that the data cannot keep up and thus becomes sparse\n",
        "\n",
        "2) The second issue that arises is related to sorting or classifying the data.  In low dimensional spaces, data may seem very similar but the higher the dimension the further these data points may seem to be."
      ],
      "metadata": {
        "id": "wCwcWSW-XugR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection:-\n",
        "\n",
        "A feature is an attribute that has an impact on a problem or is useful for the problem, and choosing the important features for the model is known as feature selection. Each machine learning process depends on feature engineering, which mainly contains two processes; which are Feature Selection and Feature Extraction. Although feature selection and extraction processes may have the same objective, both are completely different from each other. The main difference between them is that feature selection is about selecting the subset of the original feature set, whereas feature extraction creates new features. Feature selection is a way of reducing the input variable for the model by using only relevant data in order to reduce overfitting in the model.\n",
        "\n",
        "Need of Feature Selection:-\n",
        "\n",
        "1) It helps in avoiding the curse of dimensionality.\n",
        "\n",
        "2) It helps in the simplification of the model so that it can be easily interpreted by the researchers.\n",
        "\n",
        "3)It reduces the training time.\n",
        "\n",
        "4)It reduces overfitting hence enhance the generalization.\n",
        "\n",
        "Approaches for Feature Selection are:-\n",
        "\n",
        "1)Supervised Feature Selection technique:\n",
        "\n",
        "Supervised Feature selection techniques consider the target variable and can be used for the labelled dataset.\n",
        "\n",
        "2)Unsupervised Feature Selection technique:\n",
        "\n",
        "Unsupervised Feature selection techniques ignore the target variable and can be used for the unlabelled dataset.\n"
      ],
      "metadata": {
        "id": "skZlHuA2XvsY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AGNBdn9WNBR",
        "outputId": "ade39b9c-610e-498f-fa6b-e6de6d8b9dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10) (1000,)\n"
          ]
        }
      ],
      "source": [
        "# test classification dataset\n",
        "from sklearn.datasets import make_classification\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate a lda model on the dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n",
        "# define model\n",
        "model = LinearDiscriminantAnalysis()\n",
        "# define model evaluation method\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# summarize result\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "385ewndmW_NR",
        "outputId": "31e41f2a-5134-4760-ae40-5967502f56a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.894 (0.026)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "model.fit(X, y)\n",
        "# define new data\n",
        "row = [0.12777556,-3.64400522,-2.23268854,-1.82114386,1.75466361,0.1243966,1.03397657,2.35822076,1.01001752,0.56768485]\n",
        "# make a prediction\n",
        "new_value = model.predict([row])\n",
        "# summarize prediction\n",
        "print('Predicted Class: %d' % new_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we_GMPB0XbNZ",
        "outputId": "101c49e9-1d7a-478a-bdf9-526a03a392e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 1\n"
          ]
        }
      ]
    }
  ]
}